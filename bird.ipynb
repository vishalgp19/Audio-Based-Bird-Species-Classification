{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bird.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ZUw3YU0yjo"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import librosa, librosa.display, IPython.display as ipd\n",
        "import numpy as np\n",
        "from statistics import mean, median\n",
        "#import noisereduce as nr\n",
        "#import gzip\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fpru8K303rl"
      },
      "source": [
        "def extract_features(file_name):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file)\n",
        "        return None \n",
        "    return mfccsscaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j81e08ZNr7a"
      },
      "source": [
        "features = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llKFrMXO050A"
      },
      "source": [
        "test_path = ('/content/kooka')\n",
        "for file_name in os.listdir(test_path):\n",
        "  im_path =os.path.join(test_path, file_name)\n",
        "  #print(im_path)\n",
        "  try:\n",
        "    data = extract_features(im_path)\n",
        "    features.append([data, 'Laughing Kookaburra'])\n",
        "  except: continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6JSBlE-RT57"
      },
      "source": [
        "data=features\n",
        "random.shuffle(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik8oyVu609_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781d1bfb-68d8-491e-df4f-e81c57a44e93"
      },
      "source": [
        "featuresdf = pd.DataFrame(data, columns=['feature','label'])\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files')\n",
        "\n",
        "featuresdf.head(10)\n",
        "testdf=featuresdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished feature extraction from  51  files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y_5eYvUP-eo",
        "outputId": "1a5a79b7-a4b3-49f8-d776-6e726d577931"
      },
      "source": [
        "x=np.array(featuresdf['feature'].tolist())\n",
        "y=np.array(featuresdf['label'].tolist())\n",
        "label=np.array(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo02l-Wy8HoG"
      },
      "source": [
        "df=pd.DataFrame(x)\n",
        "df['lable']=np.array(y.tolist())\n",
        "df.to_csv('kooka.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_qiRD39P_Z"
      },
      "source": [
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqKRFGm9RzyH"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDI5eghHR59N"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DouQHGjnS2Re"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0xWjRtHTXcT",
        "outputId": "8235fd5e-c1db-413d-80e4-059182aaeea1"
      },
      "source": [
        "num_class= 2\n",
        "num_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSDjZKi8ULjf"
      },
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "###final layer\n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk5a8ueFeid0"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmRXwmNZe4wj"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 100\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/content/saved/checkpoint.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL0fpVuhfUjm",
        "outputId": "c6fe605e-7a85-4221-ebd2-c3edeb4e6602"
      },
      "source": [
        "test_accuracy=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9750000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "t6Cx9zSIiqlQ",
        "outputId": "d43ebaf3-7090-4c2d-9de9-71c5864d819b"
      },
      "source": [
        "filename=\"/content/xxx.mp3\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "#print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "#print(mfccs_scaled_features)\n",
        "#print(mfccs_scaled_features.shape)\n",
        "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
        "#print(predicted_label)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "prediction_class[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Crow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT_i0VAFjpz8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}